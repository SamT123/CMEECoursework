Starting weekly assessment for Sam, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 26.80 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week6, Week1, Week7, MP, Assessment, HPC, Week5, Week2, Week4, .git, Week3

Found the following files in parent directory: .gitignore, README.md

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:
**********************************************************************
*.tmp
*.DS_store
*.pyc
__pycache__
*.RHistory
.idea
.vscode
Rplots.pdf
.log
*.log**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# **2019-20 CMEE Coursework Repository**
## About
Author: Sam Turner

Repository for my CMEE coursework. The directory for each Week contains four subdirectories: **code**, **data**, **results** (empty, populated when scripts from code are run), and **sandbox** (code and data used in development).

Dependencies for each Week are specified in the README in the Week's subdirectory.

## Contents
### [Week 1](https://github.com/SamT123/CMEECoursework/tree/master/Week1)
* UNIX
* Shell scripting
* LaTex

### [Week 2](https://github.com/SamT123/CMEECoursework/tree/master/Week2)
* Python I

### [Week 3](https://github.com/SamT123/CMEECoursework/tree/master/Week3)
* R

### [Week 4](https://github.com/SamT123/CMEECoursework/tree/master/Week4)
* Stats

### [Week 5](https://github.com/SamT123/CMEECoursework/tree/master/Week5)
* Stats
* GIS

### [Week 6](https://github.com/SamT123/CMEECoursework/tree/master/Week6)
* Genomics and Bioinformatics

### [Week 7](https://github.com/SamT123/CMEECoursework/tree/master/Week7)
* Python II

## Prerequisites
### Python 3.x
`pickle`	`stringdist`
**********************************************************************

======================================================================
Looking for the weekly directories...

Found 7 weekly directories: Week1, Week2, Week3, Week4, Week5, Week6, Week7

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: Code, Data, Results

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# Week 3
Coursework for CMEE week 3.
## Topics:
* R

## Requirements
* `R 3.6`
* `Python 3.7`
* `ggplot`
* `dplyr`
* `tidyr`
* `maps`

## Contents
### [Code](https://github.com/SamT123/CMEECoursework/tree/master/Week3/Code)
**apply1.R**
* Demonstrate apply function.

**apply2.R**
* Demosntrate apply function to sum a matrix.

**autocorrelation.tex**
* .tex file to compile to autocorrelation write-up.

**basic_io.R**
* csv input and output.

**boilerplate.R**
* Demonstrate R function.

**break.R**
* Demonstrate loop break.

**browse.R**
* Demostrate browser for debugging.

**CompileLaTeX_no_bib.sh**
* Compile latex document with no bibliography.
* Example usage:
`bash CompileLaTeX_no_bib autocorrelation ../Results`

**control_flow.R**
* Demonstrate looping and control flow.

**DataWrang.R**
* Data wrangling using base R.
* Conversion from wide format to long format.

**DataWrangTidy.R**
* Data wrangling using tidyr.
* Conversion from wide format to long format.

**TreeHeight.R**
* Calculate tree heights of trees in ../Data/trees.csv.

**get_TreeHeight.R**
* Find tree heights from distance to tree and angle to treetop data for specified csv. Default data is used if none provided.
* Produces output with tree height column appended.
* Example usage:
`Rscript get_TreeHeight.R ../Data/trees.csv`

**get_TreeHeight.py**
* Find tree heights from distance to tree and angle to treetop data. Default data is used if none provided.
* Produces output with tree height column appended.
* Example usage:
`python3 get_TreeHeight.py ../Data/trees.csv`

**run_get_treeheight.sh**
* Run .R and .py treeheight programs. Uses command line input file argument, or, if absent, default input file.
* Example usage:
`bash run_get_treeheight.sh ../Data/trees.csv`

**Girko.R**
* Plots eigenvalues of random real matrix, demonstrating Girko's Circular Law.

**GPDD_Data.R**
* Plots positions of samples for species observation data.

**MyBars.R**
* Demonstrate building a plot with ggplot2.

**next.R**
* Demonstrate passing to next iteration in for loop.

**plotLin.R**
* Demonstrate building linear regression plot with ggplot2.

**PP_Lattice**
* Make lattice plots for predator size, prey size, and size ratio faceted by feeding interation type.
* Save means and medians of predator size, prey size, and size ratio, for each interaction type.

**PP_regress.R**
* Plot regressions of predator size against prey size, faceted by interaction type and predator life stage.
* Save summary statistics of each regression.

**PP_regress_loc.R**
* Calculate and save summary statistics for linear regressions of of predator size against prey size, faceted by interaction type, location, and predator life stage.

**preallocate.loc**
* Demonstrate speed advantage of preallocation for R vectors.

**Ricker.R**
* Calculate population size time series from Ricker model.

**sample.R**
* Compare speeds when using: loops vs vectorization; preallocation vs reallocation.

**TAutoCorr.R**
* Calculate p value for autocorrelation in Key West Temperature data.
* Plots 3 figures for inclusion in autocorrelation.pdf write-up:
    1. histogram of scrambled data correlation coefficients
    2. temperature time series
    3. scatter of temperature at year x vs temperature at year x+1

**try.R**
* Demonstrate try function.

**Vectorize1.R**
* Compare times to sum elements of 1000 * 1000 matrix by: looping; or by built-in sum() function.

**Vectorize1.py**
* Compare times to sum elements of 1000 * 1000 matrix by: looping; or by numpy sum() function.

**Vectorize2.R**
* Compare times to simulate 1000 stochastic Ricker runs by: looping; or vectorization with vector arithmatic.

**Vectorize2.py**
* Compare times to simulate 1000 stochastic Ricker runs by: looping; or vectorization with numpy array arithmatic.

**VectorizeTimes.sh**
* Run Vectorize1.{py, R} and Vectorize2.{py, R} to demonstrate advantage of vectorization.

### [Data](https://github.com/SamT123/CMEECoursework/tree/master/Week3/Data)
**EcolArchives-E089-51-D1.csv**
* Feeding interactions data

**GPDDFiltered.RData**
* Species observation data with locations

**KeyWestAnnualMeantemperature.RData**
* Annual temperatures in Key West for 1901-2000

**PoundHillData.csv**
* Species observation data in wide format

**PoundHillMetaData.csv**
* Metadata for PoundHill.csv dataset

**Results.csv**
* Data for bar plot demonstration

**trees.csv**
* Field data with distance to tree and angle to treetop to convert to tree height

### [Results](https://github.com/SamT123/CMEECoursework/tree/master/Week3/Results)
**autocorrelation.pdf**
* Compiled Key West autocorrelation write-up
**********************************************************************

Found following files in results directory: TreeHts.csv, PP_Results.csv, autocorrelation.pdf, trees_treeheights.csv, PP_Results_non_log.csv, Pred_Lattice.pdf, Prey_Lattice.pdf, README.md, SizeRatio_Lattice.pdf, MyBars.pdf, MyData.csv...
ideally, Results directory should be empty other than, perhaps, a readme. 

Found 33 code files: browse.R, Vectorize2.py, apply1.R, PP_regress.R, sample.R, PP_regress_loc.R, control_flow.R, get_TreeHeight.py, VectorizeTimes.sh, GPDD_Data.R, boilerplate.R, TreeHeight.R, PP_Lattice.R, next.R, Ricker.R, Girko.R, Vectorize1.R, break.R, plotLin.R, basic_io.R, run_get_treeheight.sh, CompileLaTeX_no_bib.sh, Vectorize1.py, try.R, apply2.R, get_TreeHeight.R, TAutoCorr.R, Vectorize2.R, DataWrangTidy.R, preallocate.R, DataWrang.R, MyBars.R, autocorrelation.tex

======================================================================
Testing script/code files...

======================================================================
Inspecting script file browse.R...

File contents are:
**********************************************************************
# Demonstrate browser() function for debugging

## Script: browse.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate browser() function for debugging

# clear environment
rm(list=ls())

# Exponential population growth simulation, returning population size time series
Exponential <- function(N0 = 1, r = 1, generations = 10) {
    #preallocate vector
    N <- rep(NA, generations)
    N[1] <- N0
    # Calculate population size each generation
    for (t in 2:generations){
        N[t] <- N[t-1] * exp(r)
        browser()
    }
    return(N)
}

# plot exponential population growth
plot(Exponential(), type="l", main="Exponential growth", xlab = "Generation", ylab="N")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 

**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.14550s

======================================================================
Inspecting script file Vectorize2.py...

File contents are:
**********************************************************************
"""
Runs the stochastic (with gaussian fluctuations) Ricker Equation. 
Compares speed of vectorised and non-vectorised methods.
"""

# imports
import numpy as np
import time
import math

def stochrick(p0 = (np.random.random(1000) + 0.5), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """calculate population density matrix using stochastic Ricker equation, elementwise.

    PARAMETERS
    ----------
    p0 : np.array (default np.random.random(1000) + 0.5)
        array of t0 population densities
    
    r : float, int (default 1.2)
        intrinsic popoulation growth rate

    K : float, int (default 1)
        Population carrying capacity

    sigma : float, int (default 0.2)
        standard deviation of population density noise added each timestep

    numyears : int (default 100)
        number of timesteps to run simulation for

    RETURNS
    -------
    N : np.array
        array of population densities. N[i,j] = density for population i in year j
    """

    N = np.full([numyears,len(p0)],np.nan)
    N[0,] = p0
    for i in range(len(p0)):
        for j in range(numyears):
            N[j,i]=N[j-1,i] * math.exp(r*(1-N[j-1,i]/K)+np.random.randn(1)*sigma)
    return N


def stochrickvect(p0 = (np.random.random(1000) + 0.5), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """calculate population density matrix using stochastic Ricker equation, using numpy vectorization.

    PARAMETERS
    ----------
    p0 : np.array (default np.random.random(1000) + 0.5)
        array of t0 population densities
    
    r : float, int (default 1.2)
        intrinsic popoulation growth rate

    K : float, int (default 1)
        Population carrying capacity

    sigma : float, int (default 0.2)
        standard deviation of population density noise added each timestep

    numyears : int (default 100)
        number of timesteps to run simulation for

    RETURNS
    -------
    N : np.array
        array of population densities. N[i,j] = density for population i in year j
    """

    N = np.full([numyears,len(p0)],np.nan)
    N[0,] = p0
    for j in range(numyears):
        N[j,] = N[j-1,] * math.e**(r*(1-N[j-1,]/K)+np.random.randn(len(p0))*sigma)
    return N
    

print(" Python\n--------")


start = time.time()
stochrick()
end = time.time()
print("Unvectorized:\t" + "{0:.3f}".format(end-start))


start = time.time()
stochrickvect()
end = time.time()
print("Vect (NumPy):\t" + "{0:.3f}".format(end-start))
**********************************************************************

Testing Vectorize2.py...

Vectorize2.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 100

Output (only first 500 characters): 

**********************************************************************
 Python
--------
Unvectorized:	0.424
Vect (NumPy):	0.007

**********************************************************************

Code ran without errors

Time consumed = 0.57294s

======================================================================
Inspecting script file apply1.R...

File contents are:
**********************************************************************

## Script: apply1.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrating apply() function on random matrix


# clear environment
rm(list=ls())

## Build a random matrix
M <- matrix(rnorm(100), 10, 10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print (RowMeans)

## Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

## By column
ColMeans <- apply(M, 2, mean)
print (ColMeans)**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 

**********************************************************************
 [1]  0.24511856  0.35770147  0.10579821 -0.04546735 -0.14660584 -0.38846559
 [7]  0.27615707  0.49342363 -0.21706027  0.25580195
 [1] 1.0300401 2.7484725 1.5236930 0.9358059 1.7977058 1.4205845 1.2808560
 [8] 0.3476836 1.5407417 0.6251017
 [1]  0.06664949  0.58258998  0.52431897 -0.33214204  0.35870474 -0.38098448
 [7] -0.18298612  0.03990827  0.40940812 -0.14906508

**********************************************************************

Code ran without errors

Time consumed = 0.10163s

======================================================================
Inspecting script file PP_regress.R...

File contents are:
**********************************************************************

## Script:  PP_regress.R
## Author:  Sam Turner sat19@ic.ac.uk
## About:   Plots of predator mass and prey mass linear regressions, faceted by feeding
#           interaction type and predator life stage. Summary statistics for the regressions
#           are saved to csv.


# OUTPUTS :     ../Results/PP_regress_results.csv   =   linear regression summary statistics
#               ../Results/CopyFigure.pdf           =   linear regression figure for predator vs prey mass

# clear environment
rm(list=ls())
graphics.off()

# load dependencies
require(ggplot2)
require(dplyr)

# load data
MyDF <- read.csv("../Data/EcolArchives-E089-51-D1.csv")
# convert prey mass units to grams
MyDF[MyDF$Prey.mass.unit == "mg",]$Prey.mass = MyDF[MyDF$Prey.mass.unit == "mg",]$Prey.mass / 1000
MyDF$Prey.mass.unit = "g"

print("Making plots...")

# make plot with colour representing lifestage
p <- ggplot(MyDF, aes(log(Prey.mass),log(Predator.mass), colour = Predator.lifestage))

# specify number of legend rows
p <- p + guides(fill=guide_legend(nrow=1))

# specify point shape
p <- p + geom_point(shape = 3)

# specify facet by feeding interaction type
p <- p + facet_grid(Type.of.feeding.interaction ~ .)

# add linear regression lines
p <- p + geom_smooth(method = "lm",fullrange = TRUE)

# set theme
p <- p + theme_bw()

# specify legend position and axis labels
p <- p + theme(legend.position = "bottom") + xlab("Prey mass in grams") + ylab("Predator mass in grams") 

# specify typeface
p <- p + theme(axis.text = element_text(size = 10), axis.title = element_text(size=10))
p <- p + theme(strip.text = element_text(size = I(6), face = I('bold') ))

# save figure
pdf("../Results/CopyFigure.pdf")
print(p)
graphics.off();


print("Calculating regression statistics...")
# get vectors of unique lifestages, interactions
lifestages <- as.vector(unique(MyDF$Predator.lifestage))
interactions <- as.vector(unique(MyDF$Type.of.feeding.interaction))

#calculate number of rows in output dataframe
rows = length(lifestages)*length(interactions)

# initialise dataframe with appropriate columns names
outmat <- data.frame(matrix(ncol = 7, nrow = rows))
x <- c("lifestage", "interaction", "regression.slope", "regression.intercept", "R2", "F.statistic.value",  "p-value")
colnames(outmat) <- x


i<-0

# loop over each interaction
for (interaction in interactions){
    # and over each lifestage
    for (lifestage in lifestages){
        # take the specified subset of the data
        d = MyDF[MyDF$Predator.lifestage == lifestage, ][MyDF$Type.of.feeding.interaction == interaction, ]
        
        # require at east 3 non-NA predator mass and prey mass values to fit linear model
        if ( sum(!is.na(d['Predator.mass'])) > 3 & sum(!is.na(d['Prey.mass'])) > 3){
            # fit linear model
            l=lm(Predator.mass~Prey.mass, data = MyDF[MyDF$Predator.lifestage == lifestage, ][MyDF$Type.of.feeding.interaction == interaction, ])
            # get linear model summary
            s=summary(l)
            
            # write line of output dataframe
            outmat[i,]<-c(lifestage, interaction, s$coefficients['Prey.mass','Estimate'], s$coefficients['(Intercept)','Estimate'], s$r.squared, s$fstatistic['value'], s$coefficients[2,4])
        }
        
        # if insufficient number of non-NA values, write NA to output dataframe
        else {
            outmat[i,] <- c(lifestage, interaction, NA, NA, NA, NA, NA)
        }
        i <- i + 1
    }

}

# save dataframe
write.csv(outmat, '../Results/PP_regress_results.csv')


**********************************************************************

Testing PP_regress.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Making plots..."
[1] "Calculating regression statistics..."

**********************************************************************

Encountered error (or warning):
Loading required package: ggplot2
Loading required package: dplyr

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
In qt((1 - level)/2, df) : NaNs produced

======================================================================
Inspecting script file sample.R...

File contents are:
**********************************************************************
## Script: PP_regress.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate speed benefit of preallocation and vectorization

# clear environment
rm(list=ls())

######### Functions ##########

## A function to take a sample of size n from a population "popn" and return its mean

myexperiment <- function(popn, n){
    pop_sample <- sample(popn,n,replace=FALSE)
    return(mean(pop_sample))
}

## Calculate means using a for loop without preallocation:

loopy_sample1 <- function(popn,n,num){
    result1 <- vector()
    for(i in 1:num){
        result1 <- c(result1, myexperiment(popn,n))

    }
    return(result1)
}

## To run "num" iterations of the experiment using a for loop on a vector with preallocation:

loopy_sample2 <- function(popn,n,num){
    result2 <- vector(,num)
    for(i in 1:num){
        result2[i] <- myexperiment(popn,n)
    }
    return(result2)
}

## To run "num" iterations of the experiment using a for loop on a list with preallocation:

loopy_sample3 <- function(popn, n, num){
	result3 <- vector("list", num) #Preallocate expected size
	for(i in 1:num){
		result3[[i]] <- myexperiment(popn, n)
    }
	return(result3)
}


## To run "num" iterations of the experiment using vectorization with lapply:

lapply_sample <- function(popn, n, num){
	result4 <- lapply(1:num, function(i) myexperiment(popn, n))
	return(result4)
}

## To run "num" iterations of the experiment using vectorization with lapply:
sapply_sample <- function(popn, n, num){
	result5 <- sapply(1:num, function(i) myexperiment(popn, n))
	return(result5)
}


popn <- rnorm(10000) # Generate the population
hist(popn)

n <- 20 # sample size for each experiment
num <- 10000 # Number of times to rerun the experiment

print("The loopy, non-preallocation approach takes:" )
print(system.time(loopy_sample1(popn, n, num)))

print("The loopy, but with preallocation approach takes:" )
print(system.time(loopy_sample2(popn, n, num)))

print("The loopy, preallocation list approach takes:" )
print(system.time(loopy_sample3(popn, n, num)))

print("The vectorized sapply approach takes:" )
print(system.time(sapply_sample(popn, n, num)))

print("The vectorized lapply approach takes:" )
print(system.time(lapply_sample(popn, n, num)))


**********************************************************************

Testing sample.R...

Output (only first 500 characters): 

**********************************************************************
[1] "The loopy, non-preallocation approach takes:"
   user  system elapsed 
  0.408   0.000   0.412 
[1] "The loopy, but with preallocation approach takes:"
   user  system elapsed 
  0.200   0.020   0.221 
[1] "The loopy, preallocation list approach takes:"
   user  system elapsed 
  0.200   0.044   0.242 
[1] "The vectorized sapply approach takes:"
   user  system elapsed 
  0.192   0.028   0.221 
[1] "The vectorized lapply approach takes:"
   user  system elapsed 
  0.220   0.020   0.242 

**********************************************************************

Code ran without errors

Time consumed = 1.55030s

======================================================================
Inspecting script file PP_regress_loc.R...

File contents are:
**********************************************************************
## Script: PP_regress.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Predator mass and prey mass linear regression summary statistics, faceted by feeding
#         interaction type, location, and predator life stage.

# OUTPUTS :     ../Results/PP_regress_results_loc.csv   =   linear regression summary statistics



# clear environment
rm(list=ls())

# load dependencies
require(ggplot2)
require(dplyr)

# load data
MyDF <- read.csv("../Data/EcolArchives-E089-51-D1.csv")
# convert prey mass units to grams
MyDF[MyDF$Prey.mass.unit == "mg",]$Prey.mass = MyDF[MyDF$Prey.mass.unit == "mg",]$Prey.mass / 1000
MyDF$Prey.mass.unit = "g"

# get vectors of unique lifestages, interactions, location
lifestages <- as.vector(unique(MyDF$Predator.lifestage))
interactions <- as.vector(unique(MyDF$Type.of.feeding.interaction))
locations <- as.vector(unique(MyDF$Location))

# calculate number of rows in output dataframe
rows = length(lifestages)*length(interactions)*length(locations)

# initialise output dataframe with appropriate column headings
outmat <- data.frame(matrix(ncol = 8, nrow = rows))
x <- c("lifestage", "interaction","location", "regression.slope", "regression.intercept", "R2", "F.statistic.value",  "p-value")
colnames(outmat) <- x


i<-0

# loop over interaction types, lifestages, and locations
for (interaction in interactions){
    for (lifestage in lifestages){
        for (location in locations){
            # take the specified subset of the data
            d = MyDF[MyDF$Predator.lifestage == lifestage, ][MyDF$Type.of.feeding.interaction == interaction, ][MyDF$Location == location, ]
            
            # require at east 3 non-NA predator mass and prey mass values to fit linear model
            if (sum(!is.na(d['Predator.mass'])) > 3 &  sum(!is.na(d['Prey.mass'])) > 3 ){
                
                # fit linear model
                l=lm(Predator.mass~Prey.mass, data = MyDF[MyDF$Predator.lifestage == lifestage, ][MyDF$Type.of.feeding.interaction == interaction, ])
                # get summary of linear model
                s=summary(l)
                # write line of output dataframe
                outmat[i,]<-c(lifestage, interaction,location, s$coefficients['Prey.mass','Estimate'], s$coefficients['(Intercept)','Estimate'], s$r.squared, s$fstatistic['value'], s$coefficients[2,4])
            }
            # if insufficient non-NA values, enter NA values
            else {
                outmat[i,] <- c(lifestage, interaction, location, NA, NA, NA, NA, NA)
            }
            i <- i + 1
        }
    }
}
# write output to csv
write.csv(outmat, '../Results/PP_regress_results_loc.csv')



**********************************************************************

Testing PP_regress_loc.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Loading required package: ggplot2
Loading required package: dplyr

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union


======================================================================
Inspecting script file control_flow.R...

File contents are:
**********************************************************************

## Script: control_flow.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Some code exemplifying control flow constructs in R 


# clear environment
rm(list=ls())

## If statement
a <- TRUE
if (a == TRUE){
    print ("a is TRUE")
    } else {
    print ("a is FALSE")
}

## On a single line
z <- runif(1) ##random number
if (z <= 0.5) {
    print ("Less than a half")
    }

## For loop using a sequence
for (i in 1:100){
    j <- i * i
    print(paste(i, " squared is", j ))
}

## For loop over vector of strings
for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii'))
{
  print(paste('The species is', species))
}

## for loop using a vector
v1 <- c("a","bc","def")
for (i in v1){
    print(i)
}

## While loop
i <- 0
while (i<100){
    i <- i+1
    print(i^2)
}**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 

**********************************************************************
[1] "a is TRUE"
[1] "Less than a half"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "11  squared is 121"
[1] "12  squared is 144"
[1] "13  squared is 169"
[1] "14  squared is 196"
[1] "15  squared is 225"
[1] "16  squared is 256"
[1] "17  squared is 289"
[1] "18  squared is 324"
[1] "19  squared is 361"
[1] "20 
**********************************************************************

Code ran without errors

Time consumed = 0.13204s

======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:
**********************************************************************
"""
Calculates heights of trees of trees given in input file (or default file if input file absent)
given distance of each tree from its base and angle to its top, using  the trigonometric formula:
height = distance * tan(radians)
Saves tree heights as column in ../Results/<input_name_tree_heights>_python.csv

INPUTS:
    arg1 : str  =   file path to .csv file containing tree distances and angles of elevation

OUTPUTS:
    ../Results/<input_name_tree_heights>_python.csv   =   .csv with tree heights added as column

"""

__appname__ = 'get_TreeHeight.py'
__author__ = 'Sam Turner (sat19@ic.ac.uk)'
__version__ = '0.0.1'
__license__ = 'GNU public' 

# imports
import csv
import math
import sys
import os

def TreeHeight(degrees, distance):
    """Calculate a tree height given and angle and distance to the tree
    
    PARAMETERS
    ----------
    degrees : int, float
        angle from the observer to the top of the tree in degrees
        
    distance : int, float
        distance from the observer to the tree
        
    RETURNS
    -------
    height : int, float
        height of tree in same units as distnace parameter
    """
    radians = float(degrees) * math.pi / 180
    height = float(distance) * math.tan(radians)

    return height


def main(argv):
    """
    Main entry point for program. Opens passed tree data file, or uses default. Saves output file
    with tree heights to Data directorty.
    """
    # get file name from command line arg
    if len(argv) == 1 :
        print("No input file specified: using default trees.csv")
        fname = "../Data/trees.csv"
    
    elif len(argv) > 2:
        print("please provide one input file")
        return 1
    
    else:
        fname = sys.argv[1]

    # read in tree distance and angle data
    f = open(fname)
    MyDataReader = csv.reader(f)
    temp = []
    for row in MyDataReader:
        temp.append(row)
    f.close()


    # calculate heights
    heights = ['no val' for i in range(len(temp))]
    temp[0].append("Tree.Height")
    for i in range(len(temp)-1):
        temp[i+1].append(TreeHeight(temp[i+1][2],temp[i+1][1]))


    basename = os.path.splitext(os.path.basename(fname))[0]
    writepath = "../Results/" + basename + "_treeheights_python.csv"

    # save dataset
    print("Saving output csv to "+writepath+"...")
    g = open(writepath, 'w')
    csvwrite = csv.writer(g)
    for row in temp:
        csvwrite.writerow(row)

    g.close()

    return 0


if __name__ == '__main__':
    status = main(sys.argv)
    sys.exit(status)
**********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 100

Output (only first 500 characters): 

**********************************************************************
No input file specified: using default trees.csv
Saving output csv to ../Results/trees_treeheights_python.csv...

**********************************************************************

Code ran without errors

Time consumed = 0.03570s

======================================================================
Inspecting script file VectorizeTimes.sh...

File contents are:
**********************************************************************
echo -e "Matrix sum timings:\n "
Rscript Vectorize1.R
python3 Vectorize1.py

echo -e "\n\nStochastic Ricker timings:\n "

Rscript Vectorize2.R
python3 Vectorize2.py
**********************************************************************

Testing VectorizeTimes.sh...

Output (only first 500 characters): 

**********************************************************************
Matrix sum timings:
 
 R 
---
Unvectorized:	 0.08 
Vectorized:	 0.001 

 Python
--------
Unvectorized:	0.178
Vect (NumPy):	0.001


Stochastic Ricker timings:
 
 R 
---
Unvectorized:	 0.234 
Vectorized:	 0.011 

 Python
--------
Unvectorized:	0.442
Vect (NumPy):	0.007

**********************************************************************

Code ran without errors

Time consumed = 1.52845s

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:
**********************************************************************
## Script: GPDD_Data.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Plot location of species observation data on world map

# clear workspace
rm(list=ls())

# load dependencies
require("maps")

print("Drawing map...")
# load data
load("../Data/GPDDFiltered.RData")

# draw map
map(database = "world", fill=TRUE, col="white", 
    bg = "#94e0ff", ylim = c(-60,90), border = "grey")

# add points to map
points(gpdd$long,gpdd$lat,col=2,pch=4, cex=0.5)

# There is a disproportinate number of measurements in UK and West Coast of USA.
# Results from this dataset are not necessarily representative of patterns in other regions
# (particularly those with highly disctinct climates). Similarly, there
# is a bias towards coastal regions**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Drawing map..."

**********************************************************************

Encountered error (or warning):
Loading required package: maps

======================================================================
Inspecting script file boilerplate.R...

File contents are:
**********************************************************************

## Script: boilerplate.R
## Author: Sam Turner sat19@ic.ac.uk
## About: demonstration of R functions

# clear environment
rm(list=ls())

MyFunction <- function(Arg1, Arg2){

  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type

  return (c(Arg1, Arg2)) #this is optional, but very useful
}

MyFunction(1,2) #test the function
MyFunction("Riki","Tiki") #A different test**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.12459s

======================================================================
Inspecting script file TreeHeight.R...

File contents are:
**********************************************************************
## Script:  TreeHeight.R
## Author:  Sam Turner sat19@ic.ac.uk

# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"



TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)
  print(paste("Tree height is:", height))

  return (height)
}

# read in data
MyData <- read.csv("../Data/trees.csv", header = TRUE)

# add column containing tree heights calculated using mapply
MyData$Tree.Height.m <- mapply(function (i,j) TreeHeight(i,j), MyData['Angle.degrees'], MyData['Distance.m'])

# write output csv
write.csv(MyData, "../Results/TreeHts.csv")
**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************
  [1] "Tree height is: 27.8021161438536" "Tree height is: 45.2460250644405"
  [3] "Tree height is: 14.6654828109493" "Tree height is: 14.9341751666304"
  [5] "Tree height is: 35.9703591412599" "Tree height is: 32.4102133664874"
  [7] "Tree height is: 17.4582436344144" "Tree height is: 30.1373803987097"
  [9] "Tree height is: 20.3124778877177" "Tree height is: 24.4316633466933"
 [11] "Tree height is: 27.5021323376702" "Tree height is: 25.1559006982628"
 [13] "Tree height is: 29.3924796426504" "Tre
**********************************************************************

Code ran without errors

Time consumed = 0.11854s

======================================================================
Inspecting script file PP_Lattice.R...

File contents are:
**********************************************************************

## Script: PP_Lattice.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Feeding interaction and body size plots.

# This script produces density plots and averages of prey size, predator size, and size ratio.
# Plots are faceted by feeding interaction type.
# Also saves to csv the mean and medians of predator size, prey size, and mass ratio for each 
# feeding interaction type, both logged and non-logged. 

# OUTPUTS :     ../Results/Pred_Lattice.pdf         =   density plot of predator size, faceted by feeding interation type
#               ../Results/Prey_Lattice.pdf         =   density plot of prey size, faceted by feeding interation type
#               ../Results/SizeRatio_Lattice.pdf    =   density plot of size ratio, faceted by feeding interation type
#               ../Results/PP_results_non_log.pdf   =   non-logged means and medians
#               ../Results/PP_results_non_log.pdf   =   logged means and medians

# clear environment
rm(list=ls())

# load dependencies
require(dplyr)
require(lattice)

# load data
MyDF <- read.csv("../Data/EcolArchives-E089-51-D1.csv")

# convert prey mass units to grams
MyDF[MyDF$Prey.mass.unit == "mg",]$Prey.mass = MyDF[MyDF$Prey.mass.unit == "mg",]$Prey.mass / 1000
MyDF$Prey.mass.unit = "g"

print("Making plots...")
# PREDATOR MASS #

# make density plot of predator mass faceted by Type.of.feeding.interaction
pdf("../Results/Pred_Lattice.pdf", # Open blank pdf page using a relative path
    11.7, 8.3)

densityplot(~log(Predator.mass) | Type.of.feeding.interaction, data=MyDF)
dev.off();


# PREY MASS #

# make density plot of prey mass faceted by Type.of.feeding.interaction
pdf("../Results/Prey_Lattice.pdf", # Open blank pdf page using a relative path
    11.7, 8.3)
densityplot(~log(Prey.mass) | Type.of.feeding.interaction, data=MyDF)
dev.off();


# MASS RATIO #

# make density plot of mass ratio faceted by Type.of.feeding.interaction
pdf("../Results/SizeRatio_Lattice.pdf", # Open blank pdf page using a relative path
    11.7, 8.3)
densityplot(~log(Prey.mass/Predator.mass) | Type.of.feeding.interaction, data=MyDF)
dev.off();

print("Finding means...")

# AVERAGES #

# find mean and median predator mass, prey mass, and size ratio
meanPred = mean(MyDF$Predator.mass)
medPred = median(MyDF$Predator.mass)

meanPrey = mean(MyDF$Prey.mass)
medPrey = median(MyDF$Prey.mass)

meanRatio = mean(MyDF$Prey.mass/MyDF$Predator.mass)
medRatio = median(MyDF$Prey.mass/MyDF$Predator.mass)

# save averages to output file
d = data.frame(row.names = c('predator', 'prey', 'ratio'),'mean.g'=c(meanPred,meanPrey,meanRatio),'median.g'=c(medPred,medPrey,medRatio))
write.csv(d, '../Results/PP_Results_non_log.csv')


# LOG AVERAGES #

# find means and medians of log mass, faceted by interaction type
outmat <- MyDF %>%
  group_by(Type.of.feeding.interaction) %>%
  summarize(mean_Pred = mean(log(Predator.mass), na.rm = TRUE),
            mean_Prey = mean(log(Prey.mass), na.rm = TRUE),
            mean_Ratio = mean(log(Prey.mass/Predator.mass)),
            med_Pred = median(log(Predator.mass), na.rm = TRUE),
            med_Prey = median(log(Prey.mass), na.rm = TRUE),
            med_Ratio = median(log(Prey.mass/Predator.mass)))


# produce and save matrix with appropriate column headings
outmat <- data.frame(outmat)

colnames(outmat) <- c('Feeding interaction type',
                      'Mean log Pred size (g)',
                      'Mean log Prey size (g)',
                      'Mean log Size Ratio',
                      'Median log Pred size (g)',
                      'Median log Prey size (g)',
                      'Median log Size Ratio')

write.csv(outmat, "../Results/PP_Results.csv")

**********************************************************************

Testing PP_Lattice.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Making plots..."
null device 
          1 
null device 
          1 
null device 
          1 
[1] "Finding means..."

**********************************************************************

Encountered error (or warning):
Loading required package: dplyr

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loading required package: lattice

======================================================================
Inspecting script file next.R...

File contents are:
**********************************************************************

## Script: next.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate passing to next iterator term in R

# clear environment
rm(list=ls())

for (i in 1:10) {
  if ((i %% 2) == 0) 
    next # pass to next iteration of loop 
  print(i)
}**********************************************************************

Testing next.R...

Output (only first 500 characters): 

**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.12408s

======================================================================
Inspecting script file Ricker.R...

File contents are:
**********************************************************************

## Script: Ricker.R
## Author: Sam Turner sat19@ic.ac.uk
## About: plot Ricker model time series

Ricker <- function(N0=1, r=1, K=10, generations=50)
{
  # Runs a simulation of the Ricker model
  # Returns a vector of length generations

  N <- rep(NA, generations)    # Creates a vector of NA

  N[1] <- N0
  for (t in 2:generations)
  {
    N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
  }
  return (N)
}

#plot ricker population time series
plot(Ricker(generations=10), type="l", xlab="Population size", ylab="Generation")

if (file.exists("Rplots.pdf")){
    file.remove("Rplots.pdf")
}**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 

**********************************************************************
[1] TRUE

**********************************************************************

Code ran without errors

Time consumed = 0.17188s

======================================================================
Inspecting script file Girko.R...

File contents are:
**********************************************************************

## Script: break.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate Girko's Circular law


# Girko's Circular Law: The eigenvalues of a real valued N * N matrix fall
#                       in a circle of radius √N. the distribution of these values
#                       is uniform over the unit disc in the limit of N
#
# We can illustrate this by plotting eigenvalues of real valued N x N matrix,


# clear environment
rm(list=ls())

# load dependencies
require(ggplot2)

build_ellipse <- function(hradius, vradius){ # function that returns the points on an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}


N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns

# plot the eigenvalues
pdf("../Results/Girko.pdf")

p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))
print(p)
dev.off()

if (file.exists("Rplots.pdf")){
    file.remove("Rplots.pdf")
}**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 

**********************************************************************
null device 
          1 

**********************************************************************

Encountered error (or warning):
Loading required package: ggplot2

======================================================================
Inspecting script file Vectorize1.R...

File contents are:
**********************************************************************


## Script:  Vectorize1.R
## Author:  Sam Turner sat19@ic.ac.uk
## About:   Comparison of element-wise matrix sum to built in vectorized sum function

# generate 1000 * 1000 matrix of random numbers
M <- matrix(runif(1000000),1000,1000)

# sum all elements of matrix by looping
SumAllElements <- function(M){
  Dimensions <- dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]){
    for (j in 1:Dimensions[2]){
      Tot <- Tot + M[i,j]
    }
  }
  return (Tot)
}
 
# Time built-in and loopy methods of matrix summing
cat(" R \n---\n")

cat("Unvectorized:\t", system.time(SumAllElements(M))[[3]],"\n")

cat("Vectorized:\t", system.time(sum(M))[[3]],"\n\n")
**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 

**********************************************************************
 R 
---
Unvectorized:	 0.084 
Vectorized:	 0.002 


**********************************************************************

Code ran without errors

Time consumed = 0.25934s

======================================================================
Inspecting script file break.R...

File contents are:
**********************************************************************

## Script: break.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate breaking out of loop in R

# clear environment
rm(list=ls())

i <- 0 #Initialize i
    while(i < Inf) {
        if (i == 20) {
            break 
             } # Break out of the while loop! 
        else { 
            cat("i equals " , i , " \n")
            i <- i + 1 # Update i
    }
}**********************************************************************

Testing break.R...

Output (only first 500 characters): 

**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  
i equals  10  
i equals  11  
i equals  12  
i equals  13  
i equals  14  
i equals  15  
i equals  16  
i equals  17  
i equals  18  
i equals  19  

**********************************************************************

Code ran without errors

Time consumed = 0.12592s

======================================================================
Inspecting script file plotLin.R...

File contents are:
**********************************************************************

## Script: plotLin.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate building up a plot with ggplot, on random data

# clear environment
rm(list=ls())

# load dependencies
require(ggplot2)


# generate random data
x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
             ) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                       parse = TRUE, size = 6, 
                       colour = "blue")


pdf("../Results/MyLinReg.pdf")
print(p)
dev.off()**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 

**********************************************************************
null device 
          1 

**********************************************************************

Encountered error (or warning):
Loading required package: ggplot2

======================================================================
Inspecting script file basic_io.R...

File contents are:
**********************************************************************
## File input and output in R.

## Script: basic_io.R
## Author: Sam Turner sat19@ic.ac.uk
## About: file input and output

rm(list=ls())

MyData <- read.csv("../Data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../Results/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../Results/MyData.csv",append=TRUE) # Append to it

write.csv(MyData, "../Results/MyData.csv", row.names=TRUE) # write row names

write.table(MyData, "../Results/MyData.csv", col.names=FALSE)



**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Warning message:
In write.table(MyData[1, ], file = "../Results/MyData.csv", append = TRUE) :
  appending column names to file

======================================================================
Inspecting script file run_get_treeheight.sh...

File contents are:
**********************************************************************

# check if input file path passed from command line
if [ -z "$1" ]
then
  # use default if no passed file path
  echo 'Running get_Treeheight.R'
  Rscript get_TreeHeight.R ../Data/trees.csv
  echo 'Running get_Treeheight.py'
  python3 get_TreeHeight.py ../Data/trees.csv
else
  # if passed, used specified file path
  echo 'Running get_Treeheight.R'
  Rscript get_TreeHeight.R $1
  echo 'Running get_Treeheight.py'
  python3 get_TreeHeight.py $1
fi
**********************************************************************

Testing run_get_treeheight.sh...

Output (only first 500 characters): 

**********************************************************************
Running get_Treeheight.R
[1] "Saving output csv to ../Results/trees_treeheights.csv..."
Running get_Treeheight.py
Saving output csv to ../Results/trees_treeheights_python.csv...

**********************************************************************

Code ran without errors

Time consumed = 0.14550s

======================================================================
Inspecting script file CompileLaTeX_no_bib.sh...

File contents are:
**********************************************************************
#!/bin/bash

# Author: Sam Turner sat19@ic.ac.uk
# Script: CompileLaTeX_no_bib.sh
# Desc: Compiles a pdf from [name].tex and referenced .bib file, which must be in same directory.
# [name].pdf is saved in specified directory, and opened
# Arguments: 1 -> filename for .tex file without extension
#            2 -> directory to save to
# Date: Oct 2019
if [ -z "$1" ] || [ -z "$2" ]
then
    echo "Error: require path to .tex file."
    exit
fi


pdflatex $1.tex

mv $1.pdf $2$1.pdf 
open $2$1.pdf


rm *~
rm *.aux
rm *.dvi
rm *.log
rm *.nav
rm *.out
rm *.snm
rm *.toc
rm *.bbl
rm *.blg
**********************************************************************

Testing CompileLaTeX_no_bib.sh...

Output (only first 500 characters): 

**********************************************************************
Error: require path to .tex file.

**********************************************************************

Code ran without errors

Time consumed = 0.00365s

======================================================================
Inspecting script file Vectorize1.py...

File contents are:
**********************************************************************
"""Comparison of element-wise matrix sum to built-in vectorized sum function"""

__appname__ = 'Vectorize1.py'
__author__ = 'Sam Turner (sat19@ic.ac.uk)'
__version__ = '0.0.1'
__license__ = 'GNU public' 

# imports
import numpy as np
import time

# random 1000 * 1000 matrix
M = np.random.random([1000,1000])

def sum_all_elements(M):
    """
    Calculate matrix sum by elementwise addition
    PARAMETERS
    ----------
    M : np.array
        array to sum
    
    RETURNS
    -------
    int
        sum of elements of matrix
    """
    dims  = M.shape
    t=0
    for i in range(dims[0]):
        for j in range(dims[1]):
            t += M[i,j]
    return t


# time elementwise function
start = time.time()
sum_all_elements(M)
end = time.time()

sum_elems_time = end-start

# time builtin funtion

start = time.time()
np.sum(M)
end = time.time()

sum_np_time = end-start


# print results

print(" Python\n--------")

print("Unvectorized:\t" + "{0:.3f}".format(sum_elems_time))

print("Vect (NumPy):\t" + "{0:.3f}".format(sum_np_time))
**********************************************************************

Testing Vectorize1.py...

Vectorize1.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 100

Output (only first 500 characters): 

**********************************************************************
 Python
--------
Unvectorized:	0.186
Vect (NumPy):	0.001

**********************************************************************

Code ran without errors

Time consumed = 0.34308s

======================================================================
Inspecting script file try.R...

File contents are:
**********************************************************************
## Script:  try.R
## Author:  Sam Turner sat19@ic.ac.uk
## About:   demonstrate the try function

doit <- function(popn){
	x <- sample(popn, replace = TRUE)
	if(length(unique(x)) > 30) {#only take mean if sample was sufficient
		 print(paste("Mean of this sample was:", as.character(mean(x))))
		} 
	else {
		stop("Couldn't calculate mean: too few unique values!")
		}
	}

popn <- rnorm(50)

result <- lapply(1:15, function(i) try(doit(popn), FALSE))**********************************************************************

Testing try.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Mean of this sample was: -0.181490219328417"
[1] "Mean of this sample was: -0.203679159707436"
[1] "Mean of this sample was: -0.207891600707685"
[1] "Mean of this sample was: -0.107082905337917"
[1] "Mean of this sample was: -0.0723601470482945"
[1] "Mean of this sample was: -0.0960824932065616"
[1] "Mean of this sample was: -0.150527179280476"
[1] "Mean of this sample was: -0.223418012601836"
[1] "Mean of this sample was: -0.227551875170237"
[1] "Mean of this sample was: -0.103457987282014"
**********************************************************************

Encountered error (or warning):
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!

======================================================================
Inspecting script file apply2.R...

File contents are:
**********************************************************************

## Script: apply2.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrating apply() function on random matrix

# clear environment
rm(list=ls())

SomeOperation <- function(v) {
    if (sum(v) > 0 ) {
        return (v * 100)
    }
    return (v)
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, SomeOperation))**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 

**********************************************************************
            [,1]       [,2]        [,3]      [,4]        [,5]       [,6]
 [1,]  21.863019  0.8639898 -0.68564327 -40.89547 -0.47720095  -77.11574
 [2,] 189.511667  1.7365523 -1.51509174 -33.94098 -0.63522258 -117.71278
 [3,] -52.640941 -2.5405456 -0.38501054 198.86079  0.91947639  154.41323
 [4,] -50.103089 -1.1268908 -0.95557367  52.72110 -0.59887494  227.99001
 [5,] -61.308345 -2.2892394  0.58481428 -36.07983  1.78459849  -89.63883
 [6,] -81.911507  0.7870920 -0.43750560 162.22004  1.69273817  
**********************************************************************

Code ran without errors

Time consumed = 0.12478s

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:
**********************************************************************
# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula:
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"

rm(list=ls())

TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)

  return (height)
}

# get file name from command line arg
if (length( commandArgs(trailing = T) ) == 0 ){
  print("No input file specified: using default trees.csv")
  fname = "../Data/trees.csv"
} else {
  fname = commandArgs(trailing = T)[1]
}

# read in tree distance and angle data
MyData <- read.csv(file = fname, header = TRUE)

# calculate heights
MyData$Tree.Height.m <- mapply(function (i,j) TreeHeight(i,j),MyData['Angle.degrees'], MyData['Distance.m'])

# get file basename
fbase = tools::file_path_sans_ext(basename(fname))
writepath = paste("../Results/", fbase, "_treeheights.csv", sep = "")

# save dataset
print("Saving output csv to ../Results/trees_treeheights.csv...")
write.csv(MyData, writepath)
**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************
[1] "No input file specified: using default trees.csv"
[1] "Saving output csv to ../Results/trees_treeheights.csv..."

**********************************************************************

Code ran without errors

Time consumed = 0.12386s

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:
**********************************************************************
# 
## Script:  TAutoCorr.R
## Author:  Sam Turner sat19@ic.ac.uk
## About:   Calculate approximate p value for autocorrelation in Key West
#           temperature data. Also produces 3 figures for write-up:             
#               1. histogram of scrambled data correlation coefficients         :   ../Results/AutoC.pdf
#               2. temperature time series                                      :   ../Results/TempTimeSeries.pdf
#               3. scatter of temperature at year x vs temperature at year x+1  :   ../Results/AutoCscatter.pdf

# clear environment
rm(list=ls())

# load dependencies
library(ggplot2)

# load data
load("../Data/KeyWestAnnualMeanTemperature.Rdata", .GlobalEnv)

tempdata <- ats$Temp
 
# get lag-1 autocorrelation for a vector
get_auto <- function(data){
    n <- length(data)

    data_minus_first <- data[-1]

    data_minus_last <- data[-n]

    return (cor(data_minus_last, data_minus_first))

}

# correlation coefficient for real temp data
c <- get_auto(tempdata)

# plot temperature time series
plot.new()
plot(ats$Year, ats$Temp, type="n") 
lines(ats, p=)

# plot scatter of tn vs tn+1
plot.new()
plot(tempdata[-1],tempdata[-length(tempdata)])


print("Calculating approximate p value...")

# preallocate for scrambled correlation coefficeints
scrambled_autos <- rep(NA, 100000)

# fill vector of correlation coefficients for scrambled order temperatures
for (i in 1:100000){
    scrambled <- sample(tempdata,replace = FALSE)
    scrambled_autos[i] <- get_auto(scrambled)
}


# count how often the correlation coefficient of the scrambled data exceeds that of the real value
count <- 0

for (i in 1:10000){
    if (c < scrambled_autos[i]) {
        count <- count + 1
    }
}

# print result
options(scipen=999)
print(sprintf('Approx. p value = %s',count/100000))


print("Making plots...")

# histogram of scrambled data correlation coefficients
df_scram <- data.frame(scrambled_autos)

p<-ggplot(df_scram, aes(x = scrambled_autos)) + geom_histogram(color="black", fill="white", binwidth = 0.01) + xlab( "Scrambled vector autocorrelations")

p <- p + geom_vline(aes(xintercept=c), color="red", linetype="dashed", size=1 ) 

p <- p + geom_text(x=c-0.015, y=1130, angle = 90, label="Real correlation coefficient")

p

# pdf("../Results/AutoC.pdf")
# print(p)
# dev.off()

ggsave("../Results/AutoC.pdf", width = 10, height = 7)

# scatter of x[t] vs x[n+1]

df_temp <- data.frame('x_t1' = tempdata[-1], 'x_t' = tempdata[-length(tempdata)])
q <- ggplot(df_temp, aes(x_t, x_t1)) + geom_point() + xlab( expression( paste( x[t], '/ °C'))) + ylab(expression( paste( x[t+1], '/ °C'))) + xlim(23,27) + ylim(23,27)

q

pdf("../Results/AutoCscatter.pdf")
print(q)
dev.off()

# temperature time series

df_all_temp <- data.frame('temps' = tempdata, idx = 1:length(tempdata))
r <- ggplot(ats, aes(x = Year, y = Temp)) + geom_line() + ylab("Temperature / °C")
r
# pdf("../Results/TempTimeSeries.pdf")
# print(r)
# dev.off()

ggsave("../Results/TempTimeSeries.pdf", width = 10, height = 5)


# clean up
if (file.exists("Rplots.pdf")){
    file.remove("Rplots.pdf")
}**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
Calls: load -> readChar
In addition: Warning message:
In readChar(con, 5L, useBytes = TRUE) :
  cannot open compressed file '../Data/KeyWestAnnualMeanTemperature.Rdata', probable reason 'No such file or directory'
Execution halted

======================================================================
Inspecting script file Vectorize2.R...

File contents are:
**********************************************************************


## Script:  Vectorize1.R
## Author:  Sam Turner sat19@ic.ac.uk
## About:   Runs vectorized and unvectorized stochastic
#           (with gaussian fluctuations) Ricker Eqn. 

rm(list=ls())


# Samraat's original unvectorized function

stochrick<-function(p0=runif(1000,0.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  
  for (pop in 1:length(p0)) #loop through the populations
  {
    for (yr in 2:numyears) #for each pop, loop through the years
    {
      N[yr,pop]<-N[yr-1,pop]*exp(r*(1-N[yr-1,pop]/K)+rnorm(1,0,sigma))
    }
  }
 return(N)

}

# My new vectorized function, using vector arithmatic

stochrickvect<-function(p0=runif(1000,0.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  for (yr in 2:numyears) #for each pop, loop through the years
    {
      N[yr,] <- N[yr-1,]*exp(r*(1-N[yr-1,]/K)+rnorm(1,0,sigma))
    }
  return(N)
  }




# Print results to terminal
cat(" R \n---\n")

cat("Unvectorized:\t", system.time(res2<-stochrick())[[3]],"\n")

cat("Vectorized:\t", system.time(res2<-stochrickvect())[[3]],"\n\n")


**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 

**********************************************************************
 R 
---
Unvectorized:	 0.235 
Vectorized:	 0.011 


**********************************************************************

Code ran without errors

Time consumed = 0.36235s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:
**********************************************************************
## Script: DataWrang.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Data wrangling using tidyR


################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

require(dplyr)
require(tidyr)
require(reshape2)

rm(list=ls())
############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../Data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../Data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############
dim(MyData)
dplyr::glimpse(MyData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!


colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############

?melt #check out the melt function

MyWrangledData <- tidyr::gather(TempData, key = Species, value = Count, -Cultivation,-Block,-Plot,-Quadrat)

MyWrangledData <- MyWrangledData %>%
  mutate(Cultivation = factor(Cultivation),
         Block = factor(Block),
         Plot = factor(Plot),
         Quadrat = factor(Quadrat),
         Count = as.integer(Count))

dplyr::glimpse(MyWrangledData)
dim(MyWrangledData)**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 

**********************************************************************
[1] 45 60
 chr [1:45, 1:60] "Cultivation" "Block" "Plot" "Quadrat" ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:60] "V1" "V2" "V3" "V4" ...
[1] 60 45
melt                 package:reshape2                  R Documentation

_C_o_n_v_e_r_t _a_n _o_b_j_e_c_t _i_n_t_o _a _m_o_l_t_e_n _d_a_t_a _f_r_a_m_e.

_D_e_s_c_r_i_p_t_i_o_n:

     This the generic melt function. See the following functions for
     the details about different data s
**********************************************************************

Encountered error (or warning):
Loading required package: dplyr

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loading required package: tidyr
Loading required package: reshape2

Attaching package: ‘reshape2’

The following object is masked from ‘package:tidyr’:

    smiths


======================================================================
Inspecting script file preallocate.R...

File contents are:
**********************************************************************
## Script: preallocate.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate speed benefits of vector preallocation

# reallocation for large vector is slow
reallocate <- function() {
    a <- NA

    for (i in 1:10000) {
        a <- c(a, i)
        #print(a)
        #print(object.size(a))
    }
}

# preallocation for large vector is faster
preallocate <- function() {
    a <- rep(NA, 10000)

    for (i in 1:10000) {
        a[i] <- i
        #print(a)
        #print(object.size(a))
    }
}

# compare times
print(system.time(reallocate()))
print(system.time(preallocate()))

**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 

**********************************************************************
   user  system elapsed 
  0.160   0.040   0.153 
   user  system elapsed 
  0.004   0.000   0.003 

**********************************************************************

Code ran without errors

Time consumed = 0.26839s

======================================================================
Inspecting script file DataWrang.R...

File contents are:
**********************************************************************
## Script: DataWrang.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Data wrangling using base R

################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

# clear environment
rm(list=ls())

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../Data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../Data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)


############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

#?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 

**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error (or warning):
Loading required package: reshape2

======================================================================
Inspecting script file MyBars.R...

File contents are:
**********************************************************************
## Script: MyBars.R
## Author: Sam Turner sat19@ic.ac.uk
## About: Demonstrate building up a bar plot with ggplot2.

# clear environment
rm(list=ls())


# load dependencies
require(ggplot2)

# load data
a <- read.table("../Data/Results.txt", header = TRUE)

a$ymin <- rep(0, dim(a)[1])
p <- ggplot(a)

# Plot first set of bars
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y1,
                          size = (0.5)
                          ),
                        colour = "#E69F00",
                        alpha = 1/2, show.legend = FALSE)

# Plot second set of bars
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y2,
                          size = (0.5)
                          ),
                        colour = "#56B4E9",
                        alpha = 1/2, show.legend = FALSE)

# Plot third set of bars
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y3,
                          size = (0.5)
                          ),
                        colour = "#D55E00",
                        alpha = 1/2, show.legend = FALSE)

# add annotation
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
                            scale_y_continuous("My y axis") + 
                            theme_bw() + 
                            theme(legend.position = "none") 

# save to pdf
pdf("../Results/MyBars.pdf")
print(p)
dev.off()
**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 

**********************************************************************
null device 
          1 

**********************************************************************

Encountered error (or warning):
Loading required package: ggplot2
Warning message:
Removed 91 rows containing missing values (geom_text). 

======================================================================
Inspecting script file autocorrelation.tex...

File contents are:
**********************************************************************
\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{float}
\usepackage{titling}

\setlength{\droptitle}{-10em}

\title{Temperature Autocorrelation in Key West}
\author{Sam Turner}
\date{}
\begin{document}
    \maketitle
    \begin{abstract}
    Temporal autocorrelation is found in temperatures recorded in Key West between 1901 and 2000.

    \end{abstract}


    \section{Introduction}
        When interpreting any data set, it is important to consider the process which generates the data. In the case of a time series, values may be correlated with earlier values, meaning that successive measurements are not independant. Here, we check for lag-1 autocorrelation in Key West temperature data:

        \begin{figure}[H]
        \includegraphics[width=\linewidth]{../Results/TempTimeSeries.pdf}
        \caption{Time series of Key West Temperatures}
        \label{fig:temptimeseries}
        \end{figure}
        

    \section{Materials and Methods}


        We determined the correlation coefficient between a 99-length vector containing yearly temperatures between 1901 and 1999 ($x_{t0}$), and the vector containing temperatures from 1902 and 2000 ($x_{t1}$). This correlation coefficient was compared to the correlation coefficient between similarly offset 99-length vectors obtained by discarding either the  first or last value from 100,000 random permutations of the Key West temperatures. The proportion of these values which are equal to or higher than the true correlation coeeficient gives an approximation of the probability of seeing the observed level of yearly correlation given the measurements observed and is therefore our approximate p-value. 



    \section{Results}

        We find a correlation coefficient of 0.3261697 between $x_{t0}$ and $x_{t1}$. The proportion of scrambled data correlation coefficients (our aproximate p value) which are greater than this is 0.0004:

        \begin{figure}[H]
        \includegraphics[width=\linewidth]{../Results/AutoC.pdf}
        \caption{Distribution of correlation coefficients for randomly permuted temperature vectors}
        \label{fig:corrcoef}
        \end{figure}

        \pagebreak
        \noindent
        Indeed, when we look at a scatter of $x_{t}$ against $x_{t+1}$, there appears to be a positive correlation. 


        \begin{figure}[H]
        \includegraphics[width=\linewidth]{../Results/AutoCscatter.pdf}
        \caption{Scatter of $x_{t}$ against $x_{t+1}$}
        \label{fig:scatter}
        \end{figure}

\end{document}
**********************************************************************

Testing autocorrelation.tex...

======================================================================
======================================================================
Finished running scripts

Ran into 12 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 100

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!