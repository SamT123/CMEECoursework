Starting weekly assessment for Sam, Week6

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 26.80 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week6, Week1, Week7, MP, Assessment, HPC, Week5, Week2, Week4, .git, Week3

Found the following files in parent directory: .gitignore, README.md

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:
**********************************************************************
*.tmp
*.DS_store
*.pyc
__pycache__
*.RHistory
.idea
.vscode
Rplots.pdf
.log
*.log**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# **2019-20 CMEE Coursework Repository**
## About
Author: Sam Turner

Repository for my CMEE coursework. The directory for each Week contains four subdirectories: **code**, **data**, **results** (empty, populated when scripts from code are run), and **sandbox** (code and data used in development).

Dependencies for each Week are specified in the README in the Week's subdirectory.

## Contents
### [Week 1](https://github.com/SamT123/CMEECoursework/tree/master/Week1)
* UNIX
* Shell scripting
* LaTex

### [Week 2](https://github.com/SamT123/CMEECoursework/tree/master/Week2)
* Python I

### [Week 3](https://github.com/SamT123/CMEECoursework/tree/master/Week3)
* R

### [Week 4](https://github.com/SamT123/CMEECoursework/tree/master/Week4)
* Stats

### [Week 5](https://github.com/SamT123/CMEECoursework/tree/master/Week5)
* Stats
* GIS

### [Week 6](https://github.com/SamT123/CMEECoursework/tree/master/Week6)
* Genomics and Bioinformatics

### [Week 7](https://github.com/SamT123/CMEECoursework/tree/master/Week7)
* Python II

## Prerequisites
### Python 3.x
`pickle`	`stringdist`
**********************************************************************

======================================================================
Looking for the weekly directories...

Found 7 weekly directories: Week1, Week2, Week3, Week4, Week5, Week6, Week7

The Week6 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK6...

Found the following directories: Code, Data

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# Week 6
Coursework for CMEE week 6. No Results directory as no output files are generated.
## Topics:
* Genomics and Bioinformatics


## Contents
### [Code](https://github.com/SamT123/CMEECoursework/tree/master/Week5/Code)
**Bioinf1.R**
* Practical exercise detecting polymorphisms and testing for HWE

**Bioinf2.R**	
* Calculating species divergences

**Bioinf3.R**
* Estimating population sizes using the coalescent

**Bioinf4.R**
* Inferring population structure


## [Data](https://github.com/SamT123/CMEECoursework/tree/master/Week5/Data)

**bears.csv**
* Genomes for 10 bears

**bent-toe_gecko.csv**
* Genomes for 10 bent-toe geckos

**leopard_gecko.csv**
* Genomes for 10 leopard geckos

**western_banded_gecko.csv**
* Genomes for 10 western banded geckos

**killer_whale_North.csv**
* Genomes for 10 killer whales from northern population

**killer_whale_South.csv**
* Genomes for 10 killer whales from southern population

**turtle.csv**
* Genomes for 40 turtles from 4 different loactions

**turtle.genotypes.csv**
* Genotypes for 40 turtles from 4 different loactions

**********************************************************************

Results directory missing!

Creating Results directory...

Found 4 code files: Bioinf4.R, Bioinf3.R, Bioinf2.R, Bioinf1.R

======================================================================
Testing script/code files...

======================================================================
Inspecting script file Bioinf4.R...

File contents are:
**********************************************************************

# I first do Q1 by the FST method.
# Then Q2, genetic distance vs physical distance - he doesn't show how to do this in the example code...
# Then I've copy & pasted the example code for PCA and tree annotation methods as these are simpler.

# BTW if you dont get PCA, I found this video super helpful: https://www.youtube.com/watch?v=FgakZw6K1QQ
# Or if youre lazy: https://www.youtube.com/watch?v=HMOI_lkzW08

#######################
### FST calculation ###
### --------------- ###
#######################

# we will calculate FST for each pair of populations (A vs B, A vs C etc etc)

# load in data as a matrix (MUCH faster computation than dataframe, important for big genome data)

# YOU NEED TO CHANGE FILE PATH !
alleles <- as.matrix(read.csv("../Data/turtle.csv", header = FALSE, colClasses = "numeric"))



# function to calculate average FST across whole genome of two populations, a1 and a2
# we will keep track of the sum of FSTs from all sites with
#   a) derived allele frequency > 3% (we will get a list of these sites later)
#   b) non-infinite FST = biallelic in at least one population
get_ave_FST <- function(alleles1, alleles2, high_freq){
  # start total FST counter at 0
  total <- 0
  
  # start counter of eligable, segregating sites at 0
  seg <- 0
  
  # number of sites to loop over = number of columns
  sites = dim(alleles1)[2]
  
  # get allele frequencies
  f1 <- colSums(alleles1)/20
  f2 <- colSums(alleles2)/20
  
  
  # for each site in the genome...
  for (i in 1:sites){
    
    # only consider the site if:
    # high_freq == TRUE     AND    ( biallelic in a1     OR     biallelic in a2 )
    if(high_freq[i] == TRUE & ( length(unique(alleles1[,i])) != 1 | length(unique(alleles2[,i])) != 1)) {
      # if this condition is met:
      # calculate Hs using formula from lecture
      Hs <- f1[i] * (1-f1[i]) + f2[i] * (1-f2[i])
      
      # calculate Ht using formula from lecture
      Ht <- f1[i] * (1-f1[i]) + f2[i] * (1-f2[i]) + (abs(f1[i]-f2[i])**2) / 2

      # calculate FST using formula from lecture
      fst <- ( (Ht - Hs) / Ht )

      # add the FST for this site to the total
      total <- total + fst
      # and increase the count of eligable sites by 1
      seg <- seg + 1 
    }
  }
  
  # return the mean FST = total FST / number of eligable sites included
  return (total / seg)
}



# split up the 80 genome x 2000 sites matrix into matrices containing only the genomes for a specific location
A_alleles = alleles[1:20,]
B_alleles = alleles[21:40,]
C_alleles = alleles[41:60,]
D_alleles = alleles[61:80,]

# we need to determine which sites have a derived allele frequency > 3%, to put into our FST average function
# start with a vector with FALSE for all 2000 sites
high_freq = rep(FALSE,2000)

# look at each of the 2000 sites in the full 80 genome data set
for (i in 1:2000){
  
  # if the (sum of the column / 80) > 0.03, then we can accept the site
  if (sum(alleles[,i]) / 80 > 0.03){
    # so we should set the corresponding position in the vector to TRUE 
    high_freq[i] <- 1
  }
}

# finally, print out the results, calling the function with the 2 datasets of interest and the vector of frequency acceptance
cat("Mean FSTs:","\n",
    "\nA vs B:", get_ave_FST(A_alleles, B_alleles, high_freq),
    "\nA vs C:", get_ave_FST(A_alleles, C_alleles, high_freq),
    "\nA vs D:", get_ave_FST(A_alleles, D_alleles, high_freq),
    "\nB vs C:", get_ave_FST(B_alleles, C_alleles, high_freq),
    "\nB vs D:", get_ave_FST(B_alleles, D_alleles, high_freq),
    "\nC vs D:", get_ave_FST(C_alleles, D_alleles, high_freq),"\n")


### Q2 ###

#######################
### IBD calculation ###
### --------------- ###
#######################


# load genotype data as 80 sample x 2000 site matrix
genotypes <- as.matrix(read.csv("../Data/turtle.genotypes.csv", header = FALSE,stringsAsFactors=F, colClasses = "numeric"))

# calculate pairwise euclidean distance between sample genotypes, in 80 sample x 80 sample distance matrix
# this is essentially the distance between the genomes in the 2000 diomension space where each dimension represents the genotype at one site
genetic_distance <- as.matrix(dist(genotypes))

# put one-dimensional physical distances from origin in matrix
locations <- matrix(rep(rep(c(5,10,12,50), each=10),40),ncol=40)
# subtract the transpose to get pairwise distances between populations
physical_distances = abs(locations - t(locations))

# unwrap these distance matrices into vectors and plot scatter
plot(x=c(physical_distances), y=c(genetic_distance), xlab = "Physical distance / km", ylab = "Genetic distance")




### Q1 other methods ###
### COPIED FROM example_04.R  ###

### annotate location/group on tree inferred from distance matrix

distance <- dist(genotypes)

tree <- hclust(distance)

locations_vec <- rep(c("A","B","C","D"), each=10)
plot(tree, labels=locations_vec)

### or we can do a PCA
### we can filter our low-frequency variants first
colors <- rep(c("blue","red","yellow","green"), each=5)

index <- which(apply(FUN=sum, X=genotypes, MAR=2)/(nrow(genotypes)*2)>0.03)

pca <- prcomp(genotypes[,index], center=T, scale=T)

summary(pca)

plot(pca$x[,1], pca$x[,2], col=colors, pch=1)
legend("right", legend=sort(unique(locations_vec)), col=unique(colors), pch=1)
**********************************************************************

Testing Bioinf4.R...

Output (only first 500 characters): 

**********************************************************************
Mean FSTs: 
 
A vs B: 0.1700933 
A vs C: 0.1573821 
A vs D: 0.1553019 
B vs C: 0.03422231 
B vs D: 0.03262595 
C vs D: 0.01531345 
Importance of components:
                           PC1     PC2     PC3    PC4     PC5     PC6     PC7
Standard deviation     18.2017 12.4864 10.1435 9.7565 7.27634 4.40556 3.93960
Proportion of Variance  0.3958  0.1863  0.1229 0.1137 0.06326 0.02319 0.01854
Cumulative Proportion   0.3958  0.5821  0.7050 0.8187 0.88200 0.90519 0.92374
                           PC8  
**********************************************************************

Code ran without errors

Time consumed = 0.63335s

======================================================================
Inspecting script file Bioinf3.R...

File contents are:
**********************************************************************
# Calculate Ne and SFS for North and South killer whale population
# load in data as a matrix (MUCH faster computation than dataframe, important for big genome data)

# YOU NEED TO CHANGE FILE PATH !
# Note: "cat()" esentially means "print" - so whenever this appears, we are printing a progress update to the terminal
cat("Loading data...","\n")
north <- as.matrix(read.csv("../Data/killer_whale_North.csv", header = FALSE, colClasses = "numeric"))
south <- as.matrix(read.csv("../Data/killer_whale_South.csv", header = FALSE, colClasses = "numeric"))

# check data - each row is a genome

####################
### ------------ ###
### Ne ESTIMATES ###
### ------------ ###
####################

# function to calculate tajima's theta estimate from a set on genomes, provided as a parameter called "genomes"
# theta = average num. pairwise differences = sum of pairwise differences / number of pairs 
tajimas <- function(genomes){
  
  # start pairwise_differences counter at 0
  pairwise_differences <- 0
  
  # n = number of genomes = number of rows of genomes matrix
  n <- dim(genomes)[1]
  
  cat("\t","Calculating pairwise differences for Tajima's estimator...","\n")
  
  # i : loop over the n genomes
  for (i in 1:n){
    # j : loop over every genome in the rows below i
    for (j in i:(n))
      # increase pairwise_differences by the number of differences between the i'th genome and j'th genome
      pairwise_differences <- pairwise_differences + sum(genomes[i,] != genomes[j,])
  }
  
  # return the number of pairwise_differences divided by the number of pairs, n(n-1)/2
  return (pairwise_differences / (n*(n-1)/2) )  
}

# function to calculate Watterson's theta estimate from a set on genomes, provided as a parameter called "genomes"
# theta = number of segregating sites / harmonic_series up to n-1
wattersons <- function(genomes){
  # total number of sites = number of columns of genomes matrix
  sites <- dim(genomes)[2]
  
  # n = number of genomes = number of rows of genomes matrix
  n <- dim(genomes)[1]
  
  # start pairwise_differences counter at 0
  segregating = 0
  
  cat("\t","Calculating segregating sites for Watterson's estimator...","\n\n")
  
  # loop over each of the sites ( = each column )
  for (i in 1:sites) {
    # if the length of the vector containing all unique values from the column is not 1, then the site is segregating 
    if(length(unique(genomes[,i])) != 1){
      # so we increase the segregating sites count by 1
      segregating <- segregating + 1
    }
  }
  
  # we also need to work out that denominator - this sum is called the "harmonic series"
  # start our sum at zero
  harmonic <- 0
  # add 1/k to the counter for each value of k up to n-1
  for ( k in 1:(n-1) ){
    harmonic <- harmonic + 1/k
  }
  
  # return the estimate!
  return (segregating / harmonic)
}



# check our functions work by checking the example from the lecture
cat("Running example data","\n")
example_df <- cbind(c(0,0,0,1,1), c(0,1,1,0,0), c(0,1,1,1,1))
example_tajima <- tajimas(example_df)
example_watterson <- wattersons(example_df)
cat("\n\t","Tajima's estimate:\t", example_tajima,"\n\n") # should equal 1.6
cat("\t","Watterson's estimate:\t",example_watterson,"\n\n") # should equal 1.44


# calculate the Tajima and Watterson estimate of theta for each population

cat("Calculating theta estimates for North population:","\n")
north_taj <- tajimas(north)
north_wat <- wattersons(north)

cat("Calculating theta estimates for South population:","\n")
south_taj <- tajimas(south)
south_wat <- wattersons(south)


# a function to convert from a theta estimate, mutation rate, and number of sites to an Ne estimate
theta_to_Ne <- function(theta, mu, sites){
  return (theta / (4*mu*sites))
}

# provided data
mu <- 1e-8
sites <- 50000

# calculate Ne estimates
north_taj_Ne <- theta_to_Ne(north_taj, mu, sites)
north_wat_Ne <- theta_to_Ne(north_wat, mu, sites)
south_taj_Ne <- theta_to_Ne(south_taj, mu, sites)
south_wat_Ne <- theta_to_Ne(south_wat, mu, sites)

# print Ne estimates

cat("North population  Ne by Tajima's estimator:\t", north_taj_Ne,"\n")
cat("North population  Ne by Watterson's estimator:\t", north_wat_Ne,"\n")
cat("South population  Ne by Tajima's estimator:\t", south_taj_Ne,"\n")
cat("South population  Ne by Watterson's estimator: ", south_wat_Ne,"\n\n")


#######################
### --------------- ###
### SFS CALCULATION ###
### --------------- ###
#######################

# function to calculate the Site Frequeny Spectrum of a set of genomes
# we need to count how often each possible allele frequency occurs
# first we will calculate the frequency of the derived allele at each of the 50000 sites
calc_SFS <- function(genomes){
  
  # number of sites = number of columns
  sites <- dim(genomes)[2]
  
  # number of genomes = number of rows
  n <- dim(genomes)[1]
  
  # start the frequencies vector as a vector with only NA values, and length equal to te number of frequencies we will have
  # this is done for computational efficiency
  frequencies <- rep(NA, sites)
  
  # for each site...
  cat("\t","Counting allele frequencies","\n")
  for (i in 1:sites){
    # make the corresponding position in the frequencies vector equal to the derived frequency at the site
    frequencies[i] <- (sum(genomes[,i]))
  }
  
  # now lets turn this into an SFS, = frequency of frequencies 
  
  # start with empty sfs vector
  sfs <- c()
  
  # table(vector) gives the frequency of values in the vector
  tbl <- table(frequencies)
  
  cat("\t","Counting allele frequency frequencies","\n\n")
  
  # for each frequency in the range of possible frequencies (0 = all ancestral, n = all derived)
  for (f in 0:n){
    # make the f +1 'th position in sfs equal to the number of occurances of that frequency
    sfs[f+1] <- sum(tbl[names(tbl)==f])
    
  }
  # return the SFS excluding the count for sites where all alleles are ancestral (the first entry)
  return(sfs[-1])
}

# calculate the sfs for each dataset
cat("Calculating SFS for North population:","\n")
N_sfs <- calc_SFS(north)

cat("Calculating SFS for North population:","\n")
S_sfs <- calc_SFS(south)


# make barplot of the SFSs side by side - stolen from the example_03.R script
barplot(t(cbind(N_sfs, S_sfs)), beside=T, names.arg=seq(1,nrow(south),1), legend=c("North", "South"))
**********************************************************************

Testing Bioinf3.R...

Output (only first 500 characters): 

**********************************************************************
Loading data... 
Running example data 
	 Calculating pairwise differences for Tajima's estimator... 
	 Calculating segregating sites for Watterson's estimator... 


	 Tajima's estimate:	 1.6 

	 Watterson's estimate:	 1.44 

Calculating theta estimates for North population: 
	 Calculating pairwise differences for Tajima's estimator... 
	 Calculating segregating sites for Watterson's estimator... 

Calculating theta estimates for South population: 
	 Calculating pairwise differences for Tajima's e
**********************************************************************

Code ran without errors

Time consumed = 8.78140s

======================================================================
Inspecting script file Bioinf2.R...

File contents are:
**********************************************************************
library(ape)

leopard <- read.csv("../Data/leopard_gecko.csv", header = FALSE, colClasses = "character")
bent <- read.csv("../Data/bent-toed_gecko.csv", header = FALSE, colClasses = "character")
western <- read.csv("../Data/western_banded_gecko.csv", header = FALSE, colClasses = "character")

colnames(leopard)<-1:20000
colnames(bent)<-1:20000
colnames(western)<-1:20000


# want fixed differences only
fixed_sites <- function(genomes){
  fixed = c()
  for (i in 1:dim(genomes)[2]) {
    if(dim(unique(genomes[i]))[1] == 1){
      fixed <- c(fixed, i)
    }
  }
  return (unlist(fixed))
}

cat("Finding fixed sites for leopard...","\n")
leopard_fixed <- fixed_sites(leopard)

cat("Finding fixed sites for bent-toe...","\n")
bent_fixed <- fixed_sites(bent)

cat("Finding fixed sites for western...","\n")
western_fixed <- fixed_sites(western)



get_div <- function(genome1,genome2, fixed1, fixed2){

  cat("\t","Finding shares fixed sites...","\n")
  both_fixed <- intersect(fixed1, fixed2)
  
  tot <- 0
  div <- 0
  
  g1 = genome1[1,]
  g2 = genome2[1,]
  
  cat("\t","Finding fixed diverged sites...","\n")
  
  for (i in both_fixed) {
    tot <- tot + 1
    if (g1[i] != g2[i]) {
      div <- div + 1
    }
  }
  return(c(div, tot, div/tot))
}



cat("Finding leopard / bent-toe divergence","\n")
div_leo_ben  <- get_div(leopard, bent, leopard_fixed, bent_fixed)

cat("Finding leopard / western divergence","\n")
div_leo_west <- get_div(leopard, western, leopard_fixed, western_fixed)

cat("Finding bent-toe / western divergence","\n")
div_ben_west  <- get_div(bent, western, bent_fixed, western_fixed)


# rate in MY / site
rate <- div_leo_ben[3] / (30*2)

div_time_leo_ben <-  div_leo_ben[3] / (2*rate)
div_time_leo_west <- div_leo_west[3] / (2*rate)
div_time_ben_west <- div_ben_west[3] / (2*rate)

cat("\nDivergence time leopard - bent:\t", div_time_leo_ben, " MY\n")
cat("Divergence time leopard - west:\t", div_time_leo_west, " MY\n")
cat("Divergence time bent - west:\t", div_time_ben_west, " MY\n")


text.string<-
  "((Bent_toed_gecko, Western_banded_gecko), Leopard_gecko);"
vert.tree<-read.tree(text=text.string)

plot(vert.tree,no.margin=TRUE,edge.width=2)


# without PM
get_div_new <- function(genome1,genome2){
  div <- 0
  
  cat("\t","Finding fixed diverged sites...","\n")
  
  for (i in 1:dim(genome1)[2]) {
    if (length( intersect(genome1[,i], genome2[,i]) ) == 0 ) {
      div <- div + 1
    }
  }
  
  return(div)
}

**********************************************************************

Testing Bioinf2.R...

Output (only first 500 characters): 

**********************************************************************
Finding fixed sites for leopard... 
Finding fixed sites for bent-toe... 
Finding fixed sites for western... 
Finding leopard / bent-toe divergence 
	 Finding shares fixed sites... 
	 Finding fixed diverged sites... 

**********************************************************************

Code ran without errors

Time consumed = 10.01209s

======================================================================
Inspecting script file Bioinf1.R...

File contents are:
**********************************************************************
library(stringr)

bears <- read.csv("../Data/bears.csv", header = FALSE, colClasses = "character")
colnames(bears)<-1:10000

SNPs = c()

for (i in 1:10000) {
  if(dim(unique(bears[i]))[1] != 1){
    SNPs <- c(SNPs, i)
  }
}
freq <-c()
for (SNP in SNPs){
  ref <- bears[SNP][1,]
  l <- bears[SNP]
  f<-length(l[l==ref])

  if (f<20){
    f<-40-f
  }
  freq <- c(freq, f/40)
}

barplot(freq,ylim=c(0,1))

g <- data.frame(homref = numeric(),het = numeric(), homnon = numeric())


homref = rep(0,length(SNPs))
het = rep(0,length(SNPs))
homnon = rep(0,length(SNPs))

cnt = 0


for (SNP in SNPs){
  cnt<-cnt+1
  ref <- bears[SNP][1,]
  
  for (i in 1:20){
    i<-2*i-1
    j=i+1
    pair = (bears[i:j, SNP] == ref)
    

    if (sum(pair) == 2){
      homref[cnt] <- homref[cnt]+1
    }
    
    
    if (sum(pair) == 1){
      het[cnt] <- het[cnt]+1
    }
    
    
    if (sum(pair) == 0){
      homnon[cnt] <- homnon[cnt]+1
    }

  }
}

g <- data.frame(homref,het, homnon)
colnames(g)<-c('homref', 'het', 'homnon')

g$ref = (g$homref/20+g$het/40)
g$exphomref = g$ref ^ 2
g$exphet = g$ref * (1-g$ref) * 2
g$exphomnon = (1-g$ref) ^ 2

g$chi <- rowSums(( (g[1:3] - g[5:7]*20)^2) /(g[5:7]*20))
g$sig <- (g$chi>3.84)  


g$inb <- (2 * g$ref * (1-g$ref) - g$het/20) / 2*g$het/20


barplot(g$inb)
**********************************************************************

Testing Bioinf1.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 1.51106s

======================================================================
======================================================================
Finished running scripts

Ran into 0 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 100

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!